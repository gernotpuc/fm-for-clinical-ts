{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02f7de-924d-4847-8d55-98003bc6c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import random\n",
    "from imports import *\n",
    "from functions_uc3 import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485656a-7be4-4558-bad8-34794f0649b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ume_ = pd.read_csv(\"./YOUR_PATH/YOUR_FILE.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3dce0b-18bb-4ab4-b573-3396ce21fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "data_ume_scaled, scaler_ume = process_use_case_3_data_with_scaling(data_ume_, start_date_ume, end_date_ume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec8c63-654f-4c8a-92eb-80e4fbecf968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate rolling windows \n",
    "X, y, prediction_start_dates,X_df,y_df,full_data = create_rolling_windows_with_weekday_prediction(\n",
    "    data_ume_scaled, target_col=\"shift_count\", lookback=42, horizon=28, prediction_days=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday']\n",
    ")\n",
    "valid_series_dict_full, test_series_dict_full, train_series_dict_full = ts_dictionary(full_data, X_df, y_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17f224-7c4b-4b8b-a371-b0d6dc0d4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "prediction_length=28\n",
    "def time_series_kfold_cv_simplified(model_class, valid_series_dict_full, scaler, \n",
    "                                    prediction_length, input_chunk_length, output_chunk_length, \n",
    "                                    epochs=50, n_splits=5, random_state=33):\n",
    "    \"\"\"\n",
    "    Simplified k-fold cross-validation using `valid_series_dict_full` for both training and validation.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_class: A callable that returns a new model instance (e.g., `lambda **kwargs: NBEATSModel(...)`).\n",
    "    - valid_series_dict_full: Dictionary of all available time series.\n",
    "    - scaler: Scaler used for rescaling the data.\n",
    "    - prediction_length: Prediction horizon.\n",
    "    - input_chunk_length: Input chunk length for the model.\n",
    "    - output_chunk_length: Output chunk length for the model.\n",
    "    - epochs: Number of epochs to train the model.\n",
    "    - n_splits: Number of folds.\n",
    "    - random_state: Random state for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - Fold-wise metrics and aggregated metrics.\n",
    "    \"\"\"\n",
    "    keys = list(valid_series_dict_full.keys())\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(keys)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        # Use keys to create train and validation sets\n",
    "        train_keys = [keys[i] for i in train_idx]\n",
    "        valid_keys = [keys[i] for i in valid_idx]\n",
    "\n",
    "        train_fold_series = {k: valid_series_dict_full[k] for k in train_keys}\n",
    "        valid_fold_series = {k: valid_series_dict_full[k] for k in valid_keys}\n",
    "\n",
    "        # Ensure no overlap between train and validation\n",
    "        train_fold_series, valid_fold_series = prepare_train_validation_split(\n",
    "            train_fold_series, valid_fold_series, input_chunk_length, output_chunk_length\n",
    "        )\n",
    "\n",
    "        print(f\"Fold {fold + 1}: {len(train_fold_series)} training series, {len(valid_fold_series)} validation series.\")\n",
    "\n",
    "        # Skip if no training series are left\n",
    "        if len(train_fold_series) == 0:\n",
    "            print(f\"Skipping Fold {fold + 1} due to empty training set.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize and train the model\n",
    "        model = model_class(\n",
    "            input_chunk_length=input_chunk_length,\n",
    "            output_chunk_length=prediction_length,\n",
    "            random_state=random_state,\n",
    "            epochs=epochs,\n",
    "        )\n",
    "        try:\n",
    "            model.fit(series=list(train_fold_series.values()))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting model in Fold {fold + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Truncate validation series to exclude the last `prediction_length` entries\n",
    "        truncated_valid_fold_series = {\n",
    "            key: series[:-prediction_length] for key, series in valid_fold_series.items()\n",
    "        }\n",
    "\n",
    "        # Generate predictions for truncated validation series\n",
    "        try:\n",
    "            pred = model.predict(n=prediction_length, series=list(truncated_valid_fold_series.values()), num_samples=500)\n",
    "            pred_arrays = np.array([ts.all_values() for ts in pred]).squeeze(axis=2)\n",
    "            pred_medians = np.median(pred_arrays, axis=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting in Fold {fold + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Align actual values with predictions\n",
    "        actual_values = []\n",
    "        predicted_values = []\n",
    "\n",
    "        for key, pred_series in zip(valid_keys, pred_medians):\n",
    "            actual_values.append(valid_series_dict_full[key].values()[-prediction_length:].flatten())\n",
    "            predicted_values.append(pred_series)\n",
    "\n",
    "        # Convert to NumPy arrays for consistency\n",
    "        actual_values_np = np.array(actual_values)\n",
    "        predicted_values_np = np.array(predicted_values)\n",
    "\n",
    "        # Rescale predictions\n",
    "        actual_values_rescaled = scaler.inverse_transform(actual_values_np)\n",
    "        predicted_values_rescaled = scaler.inverse_transform(predicted_values_np)\n",
    "\n",
    "        # Evaluate metrics\n",
    "        metrics = bootstrap_metrics(actual_values_rescaled.flatten(), predicted_values_rescaled.flatten())\n",
    "\n",
    "        # Store metrics for this fold\n",
    "        fold_results.append({\n",
    "            \"fold\": fold + 1,\n",
    "            \"metrics\": metrics,\n",
    "            \"predictions\": predicted_values_rescaled,\n",
    "            \"actuals\": actual_values_rescaled,\n",
    "        })\n",
    "        print(f\"Fold {fold + 1} results: {metrics}\")\n",
    "\n",
    "    # Aggregate results\n",
    "    if fold_results:\n",
    "        aggregated_metrics = {metric: np.mean([fold[\"metrics\"][metric][0] for fold in fold_results]) \n",
    "                              for metric in [\"mae\", \"mse\", \"rmse\", \"mape\", \"smape\"]}\n",
    "        print(\"Aggregated cross-validation metrics MEAN:\")\n",
    "        print(aggregated_metrics)\n",
    "        aggregated_metrics_05 = {metric: np.mean([fold[\"metrics\"][metric][1] for fold in fold_results]) \n",
    "                              for metric in [\"mae\", \"mse\", \"rmse\", \"mape\", \"smape\"]}\n",
    "        print(\"Aggregated cross-validation metrics CI-LOW:\")\n",
    "        print(aggregated_metrics_05)\n",
    "        aggregated_metrics_95 = {metric: np.mean([fold[\"metrics\"][metric][2] for fold in fold_results]) \n",
    "                              for metric in [\"mae\", \"mse\", \"rmse\", \"mape\", \"smape\"]}\n",
    "        print(\"Aggregated cross-validation metrics CI-UP:\")\n",
    "        print(aggregated_metrics_95)\n",
    "    else:\n",
    "        print(\"No valid folds to aggregate metrics.\")\n",
    "        aggregated_metrics = {}\n",
    "\n",
    "    return fold_results, aggregated_metrics\n",
    "\n",
    "import optuna\n",
    "from darts.metrics import mae\n",
    "from darts.models import NBEATSModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "import torch\n",
    "\n",
    "# Global variables to track the best model and score\n",
    "best_model = None\n",
    "best_score = float(\"inf\")\n",
    "\n",
    "def objective(trial):\n",
    "    global best_model, best_score\n",
    "    print(f\"Trial {trial.number}: Starting\")\n",
    "\n",
    "    mae_all_encounters = {}\n",
    "\n",
    "    multi_models = trial.suggest_categorical(\"multi_models\", [False, True])\n",
    "    lags = trial.suggest_int(\"lags\", 7, 20)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.3)\n",
    "    num_leaves = trial.suggest_int('num_leaves', 20, 100)\n",
    "    feature_fraction = trial.suggest_uniform('feature_fraction', 0.6, 1.0)\n",
    "    bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.6, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "    min_data_in_leaf = trial.suggest_int('min_data_in_leaf', 20, 50)\n",
    "    lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-8, 1e-2)\n",
    "    lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-8, 1e-2)\n",
    "\n",
    "    pruner = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    early_stopper = EarlyStopping(\"train_loss\", min_delta=0.001, patience=3, verbose=True)\n",
    "    callbacks = [pruner, early_stopper]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        num_workers = 4\n",
    "    else:\n",
    "        num_workers = 0\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "        \"accelerator\": \"auto\",\n",
    "        \"callbacks\": callbacks,\n",
    "    }\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    #print('multi_models', multi_models)\n",
    "    #print('lags', lags)\n",
    "\n",
    "    model = LightGBMModel(\n",
    "        lags=42,\n",
    "        output_chunk_length=prediction_length,\n",
    "        random_state=42,\n",
    "        #force_col_wise=True,\n",
    "        use_static_covariates=False,\n",
    "        multi_models=multi_models,\n",
    "        learning_rate=learning_rate,\n",
    "        num_leaves=num_leaves,\n",
    "        feature_fraction=feature_fraction,\n",
    "        bagging_fraction=bagging_fraction,\n",
    "        max_depth=max_depth,\n",
    "        min_data_in_leaf=min_data_in_leaf,\n",
    "        lambda_l1=lambda_l1,\n",
    "        lambda_l2=lambda_l2,\n",
    "        likelihood=\"quantile\",\n",
    "        quantiles=[0.05, 0.1, 0.5, 0.9, 0.95],\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "    # Perform cross-validation\n",
    "    fold_results, aggregated_metrics = time_series_kfold_cv_simplified(\n",
    "        model_class=lambda **kwargs: model,\n",
    "        valid_series_dict_full=valid_series_dict_full,\n",
    "        scaler=scaler_ume,\n",
    "        prediction_length=28,\n",
    "        input_chunk_length=42,\n",
    "        output_chunk_length=5,\n",
    "        epochs=200,\n",
    "        n_splits=5,\n",
    "    )\n",
    "\n",
    "    # Get mean MAE across folds\n",
    "    mean_mae = aggregated_metrics.get(\"mae\", float(\"inf\"))\n",
    "\n",
    "    # Update best model if current one is better\n",
    "    if mean_mae < best_score:\n",
    "        best_score = mean_mae\n",
    "        best_model = model\n",
    "\n",
    "    print(f\"Trial {trial.number}: Finished with MAE = {mean_mae}\")\n",
    "    return mean_mae\n",
    "\n",
    "def print_callback(study, trial):\n",
    "    print(f\"Best value so far: {study.best_value}, Best params: {study.best_trial.params}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set up Optuna study\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=50, callbacks=[print_callback])\n",
    "\n",
    "    # Save the best model\n",
    "    if best_model is not None:\n",
    "        best_model.save(\"YOUR_PATH\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
