{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import random\n",
    "from imports import *\n",
    "from functions_uc6 import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_ume_ = pd.read_csv(\"./YOUR_PATH/YOUR_FILE.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "data_ume_scaled, scaler_ume = process_use_case_3_data_with_scaling(data_ume_, start_date_ume, end_date_ume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate rolling windows \n",
    "X, y, prediction_start_dates,X_df,y_df,full_data = create_rolling_windows_with_weekday_prediction(\n",
    "    data_ume_scaled, target_col=\"shift_count\", lookback=42, horizon=28, prediction_days=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday','Sunday']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "\n",
    "def train_test(resampled_df, prediction_length):\n",
    "    \"\"\"Split time series data by encounter_id into training and test sets.\"\"\"\n",
    "    def split_train_test(group):\n",
    "        test_rows = group.nlargest(prediction_length, 'recorded_time')\n",
    "        train_rows = group.drop(test_rows.index)\n",
    "        return train_rows, test_rows\n",
    "\n",
    "    train_list, test_list = [], []\n",
    "    for _, group in resampled_df.groupby('encounter_id'):\n",
    "        train_rows, test_rows = split_train_test(group)\n",
    "        train_list.append(train_rows)\n",
    "        test_list.append(test_rows)\n",
    "\n",
    "    train_data = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_data = pd.concat(test_list).reset_index(drop=True)\n",
    "    return train_data, test_data\n",
    "\n",
    "def train_model_ensemble(resampled_df, prediction_length, value_to_predict, resample_rate, metric):\n",
    "    \"\"\"Train an AutoML model on time series data with AutoGluon.\"\"\"\n",
    "    resampled_df = resampled_df.rename(columns={'id': 'encounter_id', 'date': 'recorded_time'})\n",
    "\n",
    "    # Split into training and testing data\n",
    "    train_df, _ = train_test(resampled_df, prediction_length)\n",
    "    train_df = train_df[['encounter_id', 'recorded_time', value_to_predict]]\n",
    "    test_df = resampled_df[['encounter_id', 'recorded_time', value_to_predict]]\n",
    "\n",
    "    # Ensure timezone-naive timestamps\n",
    "    train_df['recorded_time'] = train_df['recorded_time'].dt.tz_localize(None)\n",
    "    test_df['recorded_time'] = test_df['recorded_time'].dt.tz_localize(None)\n",
    "\n",
    "    # Convert to TimeSeriesDataFrame\n",
    "    train_data = TimeSeriesDataFrame.from_data_frame(train_df, id_column=\"encounter_id\", timestamp_column=\"recorded_time\")\n",
    "    test_data = TimeSeriesDataFrame.from_data_frame(test_df, id_column=\"encounter_id\", timestamp_column=\"recorded_time\")\n",
    "\n",
    "    # Initialize predictor\n",
    "    predictor = TimeSeriesPredictor(\n",
    "        prediction_length=prediction_length,\n",
    "        path=\"autogluon_ensemble_uc3\",\n",
    "        target=value_to_predict,\n",
    "        eval_metric=metric,\n",
    "        freq=resample_rate,\n",
    "        verbosity=3,\n",
    "        quantile_levels=[0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    predictor.fit(\n",
    "        train_data,\n",
    "        presets=\"best_quality\",\n",
    "        num_val_windows=1,\n",
    "        time_limit=15000,\n",
    "        hyperparameters={\n",
    "\n",
    "        \"Chronos\": [\n",
    "\n",
    "            {\"model_path\": \"large\", \"ag_args\": {\"name_suffix\": \"ZeroShot\"}},\n",
    "            {\"model_path\": \"large\", \"fine_tune\": True,\"fine_tune_lr\": 1e-4, \"fine_tune_steps\": 2000, \"ag_args\": {\"name_suffix\": \"FineTuned\"}},\n",
    "            {\"model_path\": \"large\", \"fine_tune\": True, \"ag_args\": {\"name_suffix\": \"FineTuned\"}},\n",
    "\n",
    "        ],\n",
    "       },\n",
    "        enable_ensemble=False,\n",
    "    )\n",
    "\n",
    "    return predictor, train_data, test_data\n",
    "\n",
    "# Parameters\n",
    "value_to_predict = 'value'\n",
    "resample_rate = 'D'\n",
    "prediction_length = 21\n",
    "metric = 'MAE'\n",
    "\n",
    "# Train the model\n",
    "predictor, train_data, test_data = train_model_ensemble(full_data, prediction_length, value_to_predict, resample_rate, metric)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
