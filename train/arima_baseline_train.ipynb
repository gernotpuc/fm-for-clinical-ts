{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "def align_timestamps(df, col):\n",
    "    df = df.copy()\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "    df[col] = df[col].dt.tz_localize(None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def to_timeseries(df, id_col, time_col, target_col):\n",
    "    df = align_timestamps(df, time_col)\n",
    "    return TimeSeriesDataFrame.from_data_frame(\n",
    "        df[[id_col, time_col, target_col]],\n",
    "        id_column=id_col,\n",
    "        timestamp_column=time_col,\n",
    "    )\n",
    "\n",
    "def to_df(obj):\n",
    "    return obj if isinstance(obj, pd.DataFrame) else pd.DataFrame(obj)\n",
    "\n",
    "\n",
    "def bootstrap_metrics(actual, predicted, n_bootstraps=1000, alpha=0.05):\n",
    "    actual, predicted = np.array(actual), np.array(predicted)\n",
    "    n = len(actual)\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    def compute_metrics(a, p):\n",
    "        mae = np.mean(np.abs(a - p))\n",
    "        rmse = np.sqrt(np.mean((a - p) ** 2))\n",
    "        mse = np.mean((a - p) ** 2)\n",
    "        mape = np.mean(np.abs((a - p) / np.maximum(np.abs(a), 1e-8))) * 100\n",
    "        smape = 100 * np.mean(2 * np.abs(a - p) / (np.abs(a) + np.abs(p) + 1e-8))\n",
    "        return mae, rmse, mse, mape, smape\n",
    "\n",
    "    base = compute_metrics(actual, predicted)\n",
    "    boot = np.zeros((n_bootstraps, len(base)))\n",
    "    for i in range(n_bootstraps):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        boot[i, :] = compute_metrics(actual[idx], predicted[idx])\n",
    "    lower = np.percentile(boot, 100 * (alpha / 2), axis=0)\n",
    "    upper = np.percentile(boot, 100 * (1 - alpha / 2), axis=0)\n",
    "    names = [\"mae\", \"rmse\", \"mse\", \"mape\", \"smape\"]\n",
    "    return {\n",
    "        **dict(zip(names, base)),\n",
    "        **{f\"{k}_ci_lower\": l for k, l in zip(names, lower)},\n",
    "        **{f\"{k}_ci_upper\": u for k, u in zip(names, upper)},\n",
    "    }\n",
    "\n",
    "def nested_cv_autogluon(\n",
    "    resampled_df,\n",
    "    prediction_length,\n",
    "    value_to_predict,\n",
    "    resample_rate,\n",
    "    metric=\"MAE\",\n",
    "    n_outer_folds=3,\n",
    "):\n",
    "    encounter_ids = resampled_df[\"encounter_id\"].unique()\n",
    "    outer_kf = KFold(n_splits=n_outer_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    aggregated_actuals, aggregated_predictions = [], []\n",
    "    fold_results = []\n",
    "\n",
    "    print(f\"Starting Nested {n_outer_folds}-Fold Cross-Validation with AutoGluon...\")\n",
    "\n",
    "    for fold_num, (train_idx, test_idx) in enumerate(outer_kf.split(encounter_ids)):\n",
    "        print(f\"\\n--- Outer Fold {fold_num + 1}/{n_outer_folds} ---\")\n",
    "\n",
    "        train_ids = encounter_ids[train_idx]\n",
    "        test_ids = encounter_ids[test_idx]\n",
    "\n",
    "        outer_train_df = resampled_df[resampled_df[\"encounter_id\"].isin(train_ids)].copy()\n",
    "        outer_test_df = resampled_df[resampled_df[\"encounter_id\"].isin(test_ids)].copy()\n",
    "\n",
    "        # Convert to TimeSeriesDataFrame\n",
    "        train_tsf = to_timeseries(outer_train_df, \"encounter_id\", \"recorded_time\", value_to_predict)\n",
    "\n",
    "\n",
    "        predictor = TimeSeriesPredictor(\n",
    "            prediction_length=prediction_length,\n",
    "            path=f\"autogluon_outer_fold{fold_num+1}\",\n",
    "            target=value_to_predict,\n",
    "            eval_metric=metric,\n",
    "            freq=resample_rate,\n",
    "            verbosity=2,\n",
    "            quantile_levels=[0.1, 0.5, 0.9],\n",
    "        )\n",
    "\n",
    "        predictor.fit(\n",
    "            train_tsf,\n",
    "            #presets=\"best_quality\",\n",
    "            num_val_windows=1,\n",
    "            time_limit=15000,\n",
    "            hyperparameters={\n",
    "                        \"AutoARIMA\":{\"n_jobs\":3,\"max_ts_length\":14},\n",
    "                        \"NaiveModel\":{\"n_jobs\":3,\"max_ts_length\":14},\n",
    "                        \"AverageModel\":{\"n_jobs\":3,\"max_ts_length\":14},\n",
    "\n",
    "    \n",
    "        },\n",
    "            enable_ensemble=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        history_list = []\n",
    "        target_list = []\n",
    "        for eid, group in outer_test_df.groupby(\"encounter_id\"):\n",
    "            group = group.sort_values(\"recorded_time\")\n",
    "            if len(group) <= prediction_length:\n",
    "                continue  # skip too-short series\n",
    "            hist = group.iloc[:-prediction_length]\n",
    "            targ = group.iloc[-prediction_length:]\n",
    "            history_list.append(hist)\n",
    "            target_list.append(targ)\n",
    "\n",
    "        test_history_df = pd.concat(history_list)\n",
    "        test_target_df = pd.concat(target_list)\n",
    "\n",
    "        test_history_tsf = to_timeseries(test_history_df, \"encounter_id\", \"recorded_time\", value_to_predict)\n",
    "\n",
    "     \n",
    "        forecast = predictor.predict(test_history_tsf)\n",
    "        forecast_df = to_df(forecast).reset_index()\n",
    "\n",
    "   \n",
    "        forecast_df[\"timestamp\"] = pd.to_datetime(forecast_df[\"timestamp\"]).dt.tz_localize(None)\n",
    "        test_target_df[\"recorded_time\"] = pd.to_datetime(test_target_df[\"recorded_time\"]).dt.tz_localize(None)\n",
    "\n",
    "        merged = forecast_df.merge(\n",
    "            test_target_df,\n",
    "            left_on=[\"item_id\", \"timestamp\"],\n",
    "            right_on=[\"encounter_id\", \"recorded_time\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "\n",
    "        actuals = merged[value_to_predict].values\n",
    "        preds = merged[\"mean\"].values\n",
    "\n",
    "        metrics = bootstrap_metrics(actuals, preds)\n",
    "        fold_results.append(metrics)\n",
    "        print(f\"Outer Fold {fold_num+1} MAE: {metrics['mae']:.4f}\")\n",
    "\n",
    "        aggregated_actuals.extend(actuals)\n",
    "        aggregated_predictions.extend(preds)\n",
    "\n",
    " \n",
    "    final_metrics = bootstrap_metrics(np.array(aggregated_actuals), np.array(aggregated_predictions))\n",
    "\n",
    "\n",
    "    print(\"Final Nested CV Results (AutoGluon TimeSeries):\")\n",
    "\n",
    "    print(f\"MAE:   {final_metrics['mae']:.4f} (95% CI: [{final_metrics['mae_ci_lower']:.4f}, {final_metrics['mae_ci_upper']:.4f}])\")\n",
    "    print(f\"RMSE:  {final_metrics['rmse']:.4f} (95% CI: [{final_metrics['rmse_ci_lower']:.4f}, {final_metrics['rmse_ci_upper']:.4f}])\")\n",
    "    print(f\"MSE:   {final_metrics['mse']:.4f} (95% CI: [{final_metrics['mse_ci_lower']:.4f}, {final_metrics['mse_ci_upper']:.4f}])\")\n",
    "    print(f\"MAPE:  {final_metrics['mape']:.2f}% (95% CI: [{final_metrics['mape_ci_lower']:.2f}%, {final_metrics['mape_ci_upper']:.2f}%])\")\n",
    "    print(f\"sMAPE: {final_metrics['smape']:.2f}% (95% CI: [{final_metrics['smape_ci_lower']:.2f}%, {final_metrics['smape_ci_upper']:.2f}%])\")\n",
    "\n",
    "    return final_metrics, fold_results, predictor\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Generating dummy resampled_df for demo. Pls replace with your actual data.\")\n",
    "    np.random.seed(42)\n",
    "    encounter_ids = [f\"E/{i}\" for i in range(6)]\n",
    "    dfs = []\n",
    "    for eid in encounter_ids:\n",
    "        times = pd.date_range(\"2024-01-01\", periods=20, freq=\"D\")\n",
    "        values = np.random.rand(20) * 10\n",
    "        dfs.append(pd.DataFrame({\"encounter_id\": eid, \"recorded_time\": times, \"value\": values}))\n",
    "    resampled_df = pd.concat(dfs)\n",
    "\n",
    "    metrics, fold_results, predictor = nested_cv_autogluon(\n",
    "        resampled_df=resampled_df,\n",
    "        prediction_length=1,\n",
    "        value_to_predict=\"value\",\n",
    "        resample_rate=\"D\",\n",
    "        metric=\"MAE\",\n",
    "        n_outer_folds=10,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
